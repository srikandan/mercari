{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Key Takeaways from EDA:\n",
    "\n",
    "* There are 1482535 rows and 7 features in the dataset.\n",
    "    * Name\n",
    "    * Item Condition Id\n",
    "    * Category Name\n",
    "    * Brand Name\n",
    "    * Shipping\n",
    "    * Item Description\n",
    "    * Price (Target Feature)\n",
    "    \n",
    "* Target feature Price is Right Skewed data.\n",
    "\n",
    "* Mean value of Price is 16$.\n",
    "\n",
    "* 97% of products are in good condition, only small percentage is defective ones.\n",
    "\n",
    "* Shipping Cost mostly paid by the buyer.\n",
    "\n",
    "* Brand is the key factor in determining the cost of an item.\n",
    "\n",
    "* Almost 10 branded items composed 90% of product listing.\n",
    "\n",
    "* Large part of items listed are women’s products like clothing, cosmetics, etc.,\n",
    "\n",
    "* Mean price of Items under condition-5 (Poor condition) is higher than Items under condition-1 (New condition) is because of Items under condition-5 are mostly Branded items and also electronic items.\n",
    "\n",
    "* Brands like\n",
    "    * Nike\n",
    "    * Victoria’s Secret\n",
    "    * Apple\n",
    "    * PINK\n",
    "    * Louis Vuitton\n",
    "are has higher value than others item brands.\n",
    "\n",
    "* Products are classified into three groups based on price,\n",
    "    * Cheap\n",
    "    * Affordable\n",
    "    * Expensive\n",
    "\n",
    "* Cheap:\n",
    "    * Most percentage of items under this group in unbranded (i.e.) brand name is not present.\n",
    "    * It contains mostly clothing, beauty products.\n",
    "\n",
    "* Affordable:\n",
    "    * Here some branded items also present.\n",
    "    * It contains branded cloths, athletic wear, games, toys, branded beauty products.\n",
    "\n",
    "* Expensive:\n",
    "    * In this group mostly branded items are present.\n",
    "    * It contains Electronic items like Mobile phone, iPad, Game Console, Wood items, branded handbags.\n",
    "\n",
    "* When comparing cheap and affordable items, mostly same item types are present in both group but branded items are more in affordable group and hence increase in the price of a item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Techniques Used:\n",
    "* Ordinal encoding technique is used for Item Condition feature.\n",
    "\n",
    "* OneHotEncoding is used for features,\n",
    "    * Brand Name.\n",
    "    * Category (Sub Level 1, Sub Level 2, Sub Level 3).\n",
    "\n",
    "* Fasttext encoding and TFIDF are used for features,\n",
    "    * Product Name.\n",
    "    * Item Description.\n",
    "\n",
    "* New feature called Is_Bundle is created using bundled information. For bundled item Is_Bundle = 1 otherwise Is_Bundle = 0.\n",
    "\n",
    "* New feature called item_description_score is created, which have sentiment score of item description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gkiZVPt_Capf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim import corpora\n",
    "import collections\n",
    "import json\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from num2words import num2words\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "CBhkcpbfCapj",
    "outputId": "78f6d07e-9c5e-4a51-9662-2cc8554e8797"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikandan\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>sub_l1</th>\n",
       "      <th>sub_l2</th>\n",
       "      <th>sub_l3</th>\n",
       "      <th>contains_bundle</th>\n",
       "      <th>item_description_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlb cincinnati reds t shirt size xl</td>\n",
       "      <td>3</td>\n",
       "      <td>mlb</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>men</td>\n",
       "      <td>tops</td>\n",
       "      <td>t-shirts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>razer blackwidow chroma keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>keyboard great condition work like come box po...</td>\n",
       "      <td>electronics</td>\n",
       "      <td>computers &amp; tablets</td>\n",
       "      <td>components &amp; parts</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ava viv blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>adorable top hint lace key hole back pale pink...</td>\n",
       "      <td>women</td>\n",
       "      <td>tops &amp; blouses</td>\n",
       "      <td>blouse</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leather horse statue</td>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>new tag leather horse retail rm stand foot hig...</td>\n",
       "      <td>home</td>\n",
       "      <td>home décor</td>\n",
       "      <td>home décor accents</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24k gold plate rise</td>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>complete certificate authenticity</td>\n",
       "      <td>women</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>necklaces</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name  item_condition_id brand_name  \\\n",
       "train_id                                                                      \n",
       "0         mlb cincinnati reds t shirt size xl                  3        mlb   \n",
       "1            razer blackwidow chroma keyboard                  3      Razer   \n",
       "2                              ava viv blouse                  1     Target   \n",
       "3                        leather horse statue                  1       miss   \n",
       "4                         24k gold plate rise                  1       miss   \n",
       "\n",
       "          price  shipping                                   item_description  \\\n",
       "train_id                                                                       \n",
       "0          10.0         1                                               miss   \n",
       "1          52.0         0  keyboard great condition work like come box po...   \n",
       "2          10.0         1  adorable top hint lace key hole back pale pink...   \n",
       "3          35.0         1  new tag leather horse retail rm stand foot hig...   \n",
       "4          44.0         0                  complete certificate authenticity   \n",
       "\n",
       "               sub_l1               sub_l2              sub_l3  \\\n",
       "train_id                                                         \n",
       "0                 men                 tops            t-shirts   \n",
       "1         electronics  computers & tablets  components & parts   \n",
       "2               women       tops & blouses              blouse   \n",
       "3                home           home décor  home décor accents   \n",
       "4               women              jewelry           necklaces   \n",
       "\n",
       "          contains_bundle  item_description_score  \n",
       "train_id                                           \n",
       "0                       0                       0  \n",
       "1                       0                       3  \n",
       "2                       0                       3  \n",
       "3                       0                       3  \n",
       "4                       0                       2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset/train_preprocessed_2.tsv', sep='\\t', index_col='train_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "az21f1ETCapk",
    "outputId": "1cbd9a65-83e3-43e6-d66c-3ed643db454c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1476189, 10) \n",
      "\n",
      "(1476189,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['price'])\n",
    "print(X.shape, '\\n')\n",
    "\n",
    "y = df['price']\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "h7FruNyoCapk"
   },
   "outputs": [],
   "source": [
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uOToes04Capk",
    "outputId": "abdaed15-ddd3-4bca-e23d-16455add5eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033332, 10) \n",
      "\n",
      "(442857, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, '\\n')\n",
    "print(X_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033332,) \n",
      "\n",
      "(442857,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, '\\n')\n",
    "print(y_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPioOHd8Capm"
   },
   "source": [
    "# * OneHotEncoding + TFIDF:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxUFr7wNCapm"
   },
   "source": [
    "#### * OneHotEncoded Features (Brand Name, Category_Sub_1, Category_Sub_2, Category_Sub_3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "52oR8wTNCapm"
   },
   "outputs": [],
   "source": [
    "brand_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "onehot_brand_xtrain = brand_encoder.fit_transform(X_train['brand_name'].values.reshape(-1, 1))\n",
    "onehot_brand_xcv = brand_encoder.transform(X_cv['brand_name'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "shrbmtpPCapn"
   },
   "outputs": [],
   "source": [
    "sub1_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "onehot_sub_l1_xtrain = sub1_encoder.fit_transform(X_train['sub_l1'].values.reshape(-1, 1))\n",
    "onehot_sub_l1_xcv = sub1_encoder.transform(X_cv['sub_l1'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "XswdKn2qCapn"
   },
   "outputs": [],
   "source": [
    "sub2_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "onehot_sub_l2_xtrain = sub2_encoder.fit_transform(X_train['sub_l2'].values.reshape(-1, 1))\n",
    "onehot_sub_l2_xcv = sub2_encoder.transform(X_cv['sub_l2'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "C6dTBxHcCapn"
   },
   "outputs": [],
   "source": [
    "sub3_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "onehot_sub_l3_xtrain = sub3_encoder.fit_transform(X_train['sub_l3'].values.reshape(-1, 1))\n",
    "onehot_sub_l3_xcv = sub3_encoder.transform(X_cv['sub_l3'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "4A_b0S8YCapn",
    "outputId": "62669c6c-c182-4851-d113-69f1992af804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4659) (1, 10) (1, 113) (1, 857)\n"
     ]
    }
   ],
   "source": [
    "print(onehot_brand_xtrain[0].shape, onehot_sub_l1_xtrain[0].shape, onehot_sub_l2_xtrain[0].shape, onehot_sub_l3_xtrain[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sFAhWGwCapn"
   },
   "source": [
    "#### * TFIDF Vectorizer (Item Name, Item Description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "Wpjx39DlCapo"
   },
   "outputs": [],
   "source": [
    "tfidf_name = TfidfVectorizer(ngram_range=(1, 2), min_df=2, max_features=10000)\n",
    "\n",
    "tfidf_xtrain_name = tfidf_name.fit_transform(X_train['name'].values)\n",
    "tfidf_xcv_name = tfidf_name.transform(X_cv['name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "ZeQ1kiKACapo"
   },
   "outputs": [],
   "source": [
    "tfidf_description = TfidfVectorizer(ngram_range=(1, 2), min_df=10, max_features=10000)\n",
    "\n",
    "tfidf_xtrain_description = tfidf_description.fit_transform(X_train['item_description'].values)\n",
    "tfidf_xcv_description = tfidf_description.transform(X_cv['item_description'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "6beiTsIYCapo"
   },
   "outputs": [],
   "source": [
    "item_condition_xtrain = coo_matrix(X_train['item_condition_id'].values).reshape(len(X_train) ,1)\n",
    "shipping_xtrain = coo_matrix(X_train['shipping'].values).reshape(len(X_train) ,1)\n",
    "contains_bundle_xtrain = coo_matrix(X_train['contains_bundle'].values).reshape(len(X_train) ,1)\n",
    "item_description_score_xtrain = coo_matrix(X_train['item_description_score'].values).reshape(len(X_train) ,1)\n",
    "\n",
    "item_condition_xcv = coo_matrix(X_cv['item_condition_id'].values).reshape(len(X_cv) ,1)\n",
    "shipping_xcv = coo_matrix(X_cv['shipping'].values).reshape(len(X_cv) ,1)\n",
    "contains_bundle_xcv = coo_matrix(X_cv['contains_bundle'].values).reshape(len(X_cv) ,1)\n",
    "item_description_score_xcv = coo_matrix(X_cv['item_description_score'].values).reshape(len(X_cv) ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "_52SAYGjCapo"
   },
   "outputs": [],
   "source": [
    "train_tf_onehot_data = hstack([onehot_brand_xtrain, onehot_sub_l1_xtrain, onehot_sub_l2_xtrain, onehot_sub_l3_xtrain, tfidf_xtrain_name, tfidf_xtrain_description, \n",
    "                        item_condition_xtrain, shipping_xtrain, contains_bundle_xtrain, item_description_score_xtrain])\n",
    "\n",
    "cv_tf_onehot_data = hstack([onehot_brand_xcv, onehot_sub_l1_xcv, onehot_sub_l2_xcv, onehot_sub_l3_xcv, tfidf_xcv_name, tfidf_xcv_description, \n",
    "                        item_condition_xcv, shipping_xcv, contains_bundle_xcv, item_description_score_xcv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "VSQJMDk6Capo"
   },
   "outputs": [],
   "source": [
    "# scipy.sparse.save_npz('Featured Engineered dataset/train_tf_onehot_data.npz', train_tf_onehot_data)\n",
    "# scipy.sparse.save_npz('Featured Engineered dataset/cv_tf_onehot_data.npz', cv_tf_onehot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_-hkX1hCapo"
   },
   "source": [
    "# * OneHotEncoding + Fasttext:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2F0jfSumCapp"
   },
   "source": [
    "#### * Fasttext Word Embedding (Item Name, Item Description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "E6Bp6zrqCapp"
   },
   "outputs": [],
   "source": [
    "fast_item_name_train_model = FastText(sentences=[i for i in X_train['name'].str.split(' ')], size=150, window=3, min_count=2, max_vocab_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "4Vh99vrMCapp",
    "outputId": "cafc5bb5-2f79-4fd9-a1b8-32895948d799"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1033332/1033332 [01:00<00:00, 17127.29it/s]\n"
     ]
    }
   ],
   "source": [
    "name_length = 25\n",
    "\n",
    "fast_item_name_train_data = []\n",
    "for row in tqdm(X_train['name']):\n",
    "    vectors = [np.mean(fast_item_name_train_model.wv[word]) for word in row.split(' ')]\n",
    "    if len(vectors) < name_length:\n",
    "        vectors.extend([0 for i in range(name_length-len(vectors))])\n",
    "    elif len(vectors) > name_length:\n",
    "        vectors = vectors[0:name_length]\n",
    "    fast_item_name_train_data.append(vectors)\n",
    "    \n",
    "fast_item_name_train_data = np.asarray(fast_item_name_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "G1BslU0hCapp",
    "outputId": "56c02c25-d035-441a-e835-2c91fc46831b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 442857/442857 [00:25<00:00, 17253.47it/s]\n"
     ]
    }
   ],
   "source": [
    "fast_item_name_cv_data = []\n",
    "for row in tqdm(X_cv['name']):\n",
    "    vectors = [np.mean(fast_item_name_train_model.wv[word]) for word in row.split(' ')]\n",
    "    if len(vectors) < name_length:\n",
    "        vectors.extend([0 for i in range(name_length-len(vectors))])\n",
    "    elif len(vectors) > name_length:\n",
    "        vectors = vectors[0:name_length]\n",
    "    fast_item_name_cv_data.append(vectors)\n",
    "    \n",
    "fast_item_name_cv_data = np.asarray(fast_item_name_cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "-mDoJmunCapp"
   },
   "outputs": [],
   "source": [
    "fast_item_name_train_data = scipy.sparse.csr_matrix(fast_item_name_train_data)\n",
    "fast_item_name_cv_data = scipy.sparse.csr_matrix(fast_item_name_cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "T8urnaUKCapp"
   },
   "outputs": [],
   "source": [
    "fast_item_desc_train_model = FastText(sentences=[i for i in X_train['item_description'].str.split(' ')], size=200, window=3, min_count=5, max_vocab_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "UwXz-Om3Capp",
    "outputId": "7820a586-1c9a-42a8-a3f3-8cbafd701c33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1033332/1033332 [01:03<00:00, 16313.87it/s]\n"
     ]
    }
   ],
   "source": [
    "description_length = 150\n",
    "\n",
    "fast_item_description_xtrain_data = []\n",
    "for row in tqdm(X_train['name']):\n",
    "    vectors = [np.mean(fast_item_name_train_model.wv[word]) for word in row.split(' ')]\n",
    "    if len(vectors) < description_length:\n",
    "        vectors.extend([0 for i in range(description_length-len(vectors))])\n",
    "    elif len(vectors) > description_length:\n",
    "        vectors = vectors[0:description_length]\n",
    "    fast_item_description_xtrain_data.append(vectors)\n",
    "fast_item_description_xtrain_data = np.asarray(fast_item_description_xtrain_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "vmUtQlVXCapq",
    "outputId": "49b2fb45-fce6-421f-8d5b-08f0edc30981"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 442857/442857 [00:26<00:00, 16705.03it/s]\n"
     ]
    }
   ],
   "source": [
    "fast_item_description_xcv_data = []\n",
    "for row in tqdm(X_cv['name']):\n",
    "    vectors = [np.mean(fast_item_name_train_model.wv[word]) for word in row.split(' ')]\n",
    "    if len(vectors) < description_length:\n",
    "        vectors.extend([0 for i in range(description_length-len(vectors))])\n",
    "    elif len(vectors) > description_length:\n",
    "        vectors = vectors[0:description_length]\n",
    "    fast_item_description_xcv_data.append(vectors)\n",
    "fast_item_description_xcv_data = np.asarray(fast_item_description_xcv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "zNuRCgGGCapq"
   },
   "outputs": [],
   "source": [
    "fast_item_description_xtrain_data = scipy.sparse.csr_matrix(fast_item_description_xtrain_data)\n",
    "fast_item_description_xcv_data = scipy.sparse.csr_matrix(fast_item_description_xcv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "ahFTvC2eCapq"
   },
   "outputs": [],
   "source": [
    "train_fasttext_onehot_data = hstack([onehot_brand_xtrain, onehot_sub_l1_xtrain, onehot_sub_l2_xtrain, onehot_sub_l3_xtrain, fast_item_name_train_data, fast_item_description_xtrain_data, \n",
    "                        item_condition_xtrain, shipping_xtrain, contains_bundle_xtrain, item_description_score_xtrain])\n",
    "\n",
    "cv_fasttext_onehot_data = hstack([onehot_brand_xcv, onehot_sub_l1_xcv, onehot_sub_l2_xcv, onehot_sub_l3_xcv, fast_item_name_cv_data, fast_item_description_xcv_data, \n",
    "                        item_condition_xcv, shipping_xcv, contains_bundle_xcv, item_description_score_xcv]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "t8Nv226QCapr"
   },
   "outputs": [],
   "source": [
    "# scipy.sparse.save_npz('Featured Engineered dataset/train_fasttext_onehot_data.npz', train_fasttext_onehot_data)\n",
    "# scipy.sparse.save_npz('Featured Engineered dataset/cv_fasttext_onehot_data.npz', cv_fasttext_onehot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRfBMkGDCapr"
   },
   "source": [
    "### * Data Loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1XWkLJ6xCapr"
   },
   "outputs": [],
   "source": [
    "train_tf_onehot_data = scipy.sparse.load_npz('Featured Engineered dataset/train_tf_onhot_data.npz')\n",
    "cv_tf_onhot_data = scipy.sparse.load_npz('Featured Engineered dataset/cv_tf_onhot_data.npz')\n",
    "\n",
    "train_fast_onehot_data = scipy.sparse.load_npz('Featured Engineered dataset/train_fasttext_onehot_data.npz')\n",
    "cv_fast_onhot_data = scipy.sparse.load_npz('Featured Engineered dataset/cv_fasttext_onehot_data.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy1D_d8cCapr"
   },
   "source": [
    "### * Linear Regressiojn Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSLRGA8UCapr"
   },
   "source": [
    "#### 1. Linear Regression Model with OneHotEcoder + TFIDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'alpha': [0.1,0.01,0.001],\n",
    "    'learning_rate': ['constant','optimal','invscaling','adaptive'],\n",
    "    'max_iter': [100, 1000, 1500, 2000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8U88Xau0Capr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed: 57.4min\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed: 116.3min\n",
      "[Parallel(n_jobs=8)]: Done 480 out of 480 | elapsed: 175.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SGDRegressor(), n_jobs=8,\n",
       "             param_grid={'alpha': [0.1, 0.01, 0.001],\n",
       "                         'learning_rate': ['constant', 'optimal', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'max_iter': [100, 1000, 1500, 2000]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SGDRegressor()\n",
    "linear_regression = GridSearchCV(estimator=model, param_grid=params, cv=10, n_jobs=8, verbose=2)\n",
    "linear_regression.fit(X=train_tf_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001, 'learning_rate': 'adaptive', 'max_iter': 100}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "F3ihhBcKCapr"
   },
   "outputs": [],
   "source": [
    "predicted = linear_regression.predict(cv_tf_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "x4X3xBOFCaps"
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in predicted.tolist():\n",
    "    if i<0:\n",
    "        temp.append(0.0)\n",
    "    else:\n",
    "        temp.append(i) \n",
    "        \n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TXeQKE1sCaps",
    "outputId": "bbee12d3-d605-44d3-b17c-aab3ed88264b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Accuracy : 0.6288816370284527\n"
     ]
    }
   ],
   "source": [
    "print('Linear Regression Accuracy :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMm-Min_Caps"
   },
   "source": [
    "#### 2. Linear Regression Model with OneHotEcoder + Fasttext:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed: 36.9min\n",
      "[Parallel(n_jobs=8)]: Done 240 out of 240 | elapsed: 59.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SGDRegressor(), n_jobs=8,\n",
       "             param_grid={'alpha': [0.1, 0.01, 0.001],\n",
       "                         'learning_rate': ['constant', 'optimal', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'max_iter': [100, 1000, 1500, 2000]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SGDRegressor()\n",
    "linear_regression = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=8, verbose=2)\n",
    "linear_regression.fit(X=train_fast_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001, 'learning_rate': 'adaptive', 'max_iter': 1000}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "mYwEXTG6Caps"
   },
   "outputs": [],
   "source": [
    "predicted = linear_regression.predict(cv_fast_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "p_082SxECaps"
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in predicted.tolist():\n",
    "    if i<0:\n",
    "        temp.append(0.0)\n",
    "    else:\n",
    "        temp.append(i) \n",
    "        \n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYEA9DKqCaps",
    "outputId": "714a83e4-bdcd-41fc-fea2-ed63d8f6ed02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Accuracy (OneHotEcoder + Fasttext) : 0.6638830712659046\n"
     ]
    }
   ],
   "source": [
    "print('Linear Regression Accuracy (OneHotEcoder + Fasttext) :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvu8pO0yOk19"
   },
   "source": [
    "#### 3. Ridge Regression Model with OneHotEcoder + TFIDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'alpha': [0.1,0.01,0.001],\n",
    "    'learning_rate': ['constant','optimal','invscaling','adaptive'],\n",
    "    'max_iter': [100, 1000, 1500, 2000],\n",
    "    'penalty': ['l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': [0.1, 0.01, 0.001],\n",
       " 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
       " 'max_iter': [100, 1000, 1500, 2000],\n",
       " 'penalty': ['l2']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed: 48.3min\n",
      "[Parallel(n_jobs=8)]: Done 240 out of 240 | elapsed: 78.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SGDRegressor(), n_jobs=8,\n",
       "             param_grid={'alpha': [0.1, 0.01, 0.001],\n",
       "                         'learning_rate': ['constant', 'optimal', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'max_iter': [100, 1000, 1500, 2000],\n",
       "                         'penalty': ['l2']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SGDRegressor()\n",
    "ridge_regression = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=8, verbose=2)\n",
    "ridge_regression.fit(X=train_tf_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ap2bU4YPDfgP",
    "outputId": "60ecce3d-65db-481a-9e7c-16ddc1019236"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001,\n",
       " 'learning_rate': 'adaptive',\n",
       " 'max_iter': 2000,\n",
       " 'penalty': 'l2'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3v0zXRI2Oo63"
   },
   "outputs": [],
   "source": [
    "predicted = ridge_regression.predict(cv_tf_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "NwE3WsvPOo4F"
   },
   "outputs": [],
   "source": [
    "temp = []\r\n",
    "for i in predicted.tolist():\r\n",
    "    if i<0:\r\n",
    "        temp.append(0.0)\r\n",
    "    else:\r\n",
    "        temp.append(i) \r\n",
    "        \r\n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLGQYSuwOo1d",
    "outputId": "d5ceb6e5-abc9-403e-b227-f5ce0c92a1ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Accuracy (OneHotEcoder + TFIDF) : 0.6288773326651926\n"
     ]
    }
   ],
   "source": [
    "print('Ridge Regression Accuracy (OneHotEcoder + TFIDF) :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfcgR59UPunV"
   },
   "source": [
    "#### 4. Ridge Regression Model with OneHotEcoder + Fasttext:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'alpha': [0.1,0.01,0.001],\n",
    "    'learning_rate': ['constant','optimal','invscaling','adaptive'],\n",
    "    'max_iter': [100, 1000, 1500, 2000],\n",
    "    'penalty': ['l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': [0.1, 0.01, 0.001],\n",
       " 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
       " 'max_iter': [100, 1000, 1500, 2000],\n",
       " 'penalty': ['l2']}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:   52.6s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed: 36.9min\n",
      "[Parallel(n_jobs=8)]: Done 240 out of 240 | elapsed: 59.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SGDRegressor(), n_jobs=8,\n",
       "             param_grid={'alpha': [0.1, 0.01, 0.001],\n",
       "                         'learning_rate': ['constant', 'optimal', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'max_iter': [100, 1000, 1500, 2000],\n",
       "                         'penalty': ['l2']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SGDRegressor()\n",
    "ridge_regression = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=8, verbose=2)\n",
    "ridge_regression.fit(X=train_fast_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "e8_v3gcAPunY"
   },
   "outputs": [],
   "source": [
    "predicted = ridge_regression.predict(cv_fast_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "CdE0fHApPunY"
   },
   "outputs": [],
   "source": [
    "temp = []\r\n",
    "for i in predicted.tolist():\r\n",
    "    if i<0:\r\n",
    "        temp.append(0.0)\r\n",
    "    else:\r\n",
    "        temp.append(i) \r\n",
    "        \r\n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UYtiaVAaPunY",
    "outputId": "61b07a5f-7785-414c-eec1-59edae237e2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Accuracy (OneHotEcoder + Fasttext) : 0.6636822822507776\n"
     ]
    }
   ],
   "source": [
    "print('Ridge Regression Accuracy (OneHotEcoder + Fasttext) :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPz-aQjPbdEr"
   },
   "source": [
    "#### 5. Lasso Regression Model with OneHotEcoder + TFIDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'alpha': [0.1,0.01,0.001],\n",
    "    'learning_rate': ['constant','optimal','invscaling','adaptive'],\n",
    "    'max_iter': [100, 1000, 1500, 2000],\n",
    "    'penalty': ['l1']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': [0.1, 0.01, 0.001],\n",
       " 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
       " 'max_iter': [100, 1000, 1500, 2000],\n",
       " 'penalty': ['l1']}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed: 61.9min\n",
      "[Parallel(n_jobs=8)]: Done 240 out of 240 | elapsed: 107.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SGDRegressor(), n_jobs=8,\n",
       "             param_grid={'alpha': [0.1, 0.01, 0.001],\n",
       "                         'learning_rate': ['constant', 'optimal', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'max_iter': [100, 1000, 1500, 2000],\n",
       "                         'penalty': ['l1']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SGDRegressor()\n",
    "lasso_regression = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=8, verbose=2)\n",
    "lasso_regression.fit(X=train_tf_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BWL2Af_BbdEv",
    "outputId": "3e2d7864-4b59-404f-e3ce-4522a80e05f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001,\n",
       " 'learning_rate': 'adaptive',\n",
       " 'max_iter': 2000,\n",
       " 'penalty': 'l1'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "bmpAaiZnbdEv"
   },
   "outputs": [],
   "source": [
    "predicted = lasso_regression.predict(cv_tf_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "YUNgmfifbdEv"
   },
   "outputs": [],
   "source": [
    "temp = []\r\n",
    "for i in predicted.tolist():\r\n",
    "    if i<0:\r\n",
    "        temp.append(0.0)\r\n",
    "    else:\r\n",
    "        temp.append(i) \r\n",
    "        \r\n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYbKwtVDbdEv",
    "outputId": "5d5ed038-b293-480d-d80d-d2cf55e2051a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Accuracy (OneHotEcoder + TFIDF) : 0.6541920512368966\n"
     ]
    }
   ],
   "source": [
    "print('Lasso Regression Accuracy (OneHotEcoder + TFIDF) :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_FM9PR3bdEw"
   },
   "source": [
    "#### 6. Lasso Regression Model with OneHotEcoder + Fasttext:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed: 38.5min\n",
      "[Parallel(n_jobs=8)]: Done 240 out of 240 | elapsed: 66.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SGDRegressor(), n_jobs=8,\n",
       "             param_grid={'alpha': [0.1, 0.01, 0.001],\n",
       "                         'learning_rate': ['constant', 'optimal', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'max_iter': [100, 1000, 1500, 2000],\n",
       "                         'penalty': ['l1']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SGDRegressor()\n",
    "lasso_regression = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=8, verbose=2)\n",
    "lasso_regression.fit(X=train_fast_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001,\n",
       " 'learning_rate': 'adaptive',\n",
       " 'max_iter': 1000,\n",
       " 'penalty': 'l1'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "bjfWFpYqbdEw"
   },
   "outputs": [],
   "source": [
    "predicted = lasso_regression.predict(cv_fast_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in predicted.tolist():\n",
    "    if i<0:\n",
    "        temp.append(0.0)\n",
    "    else:\n",
    "        temp.append(i) \n",
    "        \n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kE7wHYxibdEw",
    "outputId": "322d1eae-08e8-4a96-d65c-c317170a8998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Accuracy (OneHotEcoder + Fasttext) : 0.6598378544741845\n"
     ]
    }
   ],
   "source": [
    "print('Lasso Regression Accuracy (OneHotEcoder + Fasttext) :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzScXx9lQ_Mg"
   },
   "source": [
    "#### 7. Elasticnet Regression Model with OneHotEcoder + TFIDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'alpha': [0.1,0.01,0.001],\n",
    "    'learning_rate': ['constant','optimal','invscaling','adaptive'],\n",
    "    'max_iter': [100, 1000, 1500, 2000],\n",
    "    'penalty': ['elasticnet']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed: 59.6min\n",
      "[Parallel(n_jobs=8)]: Done 240 out of 240 | elapsed: 173.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SGDRegressor(), n_jobs=8,\n",
       "             param_grid={'alpha': [0.1, 0.01, 0.001],\n",
       "                         'learning_rate': ['constant', 'optimal', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'max_iter': [100, 1000, 1500, 2000],\n",
       "                         'penalty': ['elasticnet']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SGDRegressor()\n",
    "elastic_regression = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=8, verbose=2)\n",
    "elastic_regression.fit(X=train_tf_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001,\n",
       " 'learning_rate': 'adaptive',\n",
       " 'max_iter': 2000,\n",
       " 'penalty': 'elasticnet'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = elastic_regression.predict(cv_tf_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in predicted.tolist():\n",
    "    if i<0:\n",
    "        temp.append(0.0)\n",
    "    else:\n",
    "        temp.append(i) \n",
    "        \n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet Regression Accuracy (OneHotEcoder + TFIDF) : 0.6304825100976332\n"
     ]
    }
   ],
   "source": [
    "print('Elasticnet Regression Accuracy (OneHotEcoder + TFIDF) :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gj0phxsZQ_Ml"
   },
   "source": [
    "#### 8. Elasticnet Regression Model with OneHotEcoder + Fasttext:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'alpha': [0.1,0.01,0.001],\n",
    "    'learning_rate': ['constant','optimal','invscaling','adaptive'],\n",
    "    'max_iter': [100, 1000, 1500, 2000],\n",
    "    'penalty': ['elasticnet']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed: 21.2min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 43.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SGDRegressor(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.1, 0.01, 0.001],\n",
       "                         'learning_rate': ['constant', 'optimal', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'max_iter': [100, 1000, 1500, 2000],\n",
       "                         'penalty': ['elasticnet']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SGDRegressor()\n",
    "elastic_regression = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=-1, verbose=2)\n",
    "elastic_regression.fit(X=train_fast_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "brwFwdljQ_Ml"
   },
   "outputs": [],
   "source": [
    "predicted = elastic_regression.predict(cv_fast_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MOAyZm1VQ_Ml"
   },
   "outputs": [],
   "source": [
    "temp = []\r\n",
    "for i in predicted.tolist():\r\n",
    "    if i<0:\r\n",
    "        temp.append(0.0)\r\n",
    "    else:\r\n",
    "        temp.append(i) \r\n",
    "        \r\n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZAvYzeZwQ_Mm",
    "outputId": "322d1eae-08e8-4a96-d65c-c317170a8998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Regression Accuracy (OneHotEcoder + Fasttext) : 0.662499648269813\n"
     ]
    }
   ],
   "source": [
    "print('ElasticNet Regression Accuracy (OneHotEcoder + Fasttext) :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Decision Tree Regression Model with OneHotEcoder + TFIDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'criterion': ['mse', 'friedman_mse'],\n",
    "    'splitter': ['best'],\n",
    "    'max_depth': [10, 50, 100],\n",
    "    'min_samples_split': [2, 6, 8],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': ['mse', 'friedman_mse'],\n",
       " 'splitter': ['best'],\n",
       " 'max_depth': [10, 50, 100],\n",
       " 'min_samples_split': [2, 6, 8],\n",
       " 'max_features': ['sqrt', 'log2']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=8)]: Done 180 out of 180 | elapsed: 14.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(), n_jobs=8,\n",
       "             param_grid={'criterion': ['mse', 'friedman_mse'],\n",
       "                         'max_depth': [10, 50, 100],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'min_samples_split': [2, 6, 8], 'splitter': ['best']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor()\n",
    "dt_regression = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=8, verbose=2)\n",
    "dt_regression.fit(X=train_tf_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'max_depth': 50,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_split': 8,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = dt_regression.predict(cv_tf_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in predicted.tolist():\n",
    "    if i<0:\n",
    "        temp.append(0.0)\n",
    "    else:\n",
    "        temp.append(i) \n",
    "        \n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression Accuracy (OneHotEcoder + TFIDF) : 0.7232429983948581\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree Regression Accuracy (OneHotEcoder + TFIDF) :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Decision Tree Regression Model with OneHotEcoder + FastText:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'criterion': ['mse', 'friedman_mse'],\n",
    "    'splitter': ['best'],\n",
    "    'max_depth': [10, 50, 100],\n",
    "    'min_samples_split': [2, 6, 8],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': ['mse', 'friedman_mse'],\n",
       " 'splitter': ['best'],\n",
       " 'max_depth': [10, 50, 100],\n",
       " 'min_samples_split': [2, 6, 8],\n",
       " 'max_features': ['sqrt', 'log2']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=8)]: Done 180 out of 180 | elapsed: 27.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(), n_jobs=8,\n",
       "             param_grid={'criterion': ['mse', 'friedman_mse'],\n",
       "                         'max_depth': [10, 50, 100],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'min_samples_split': [2, 6, 8], 'splitter': ['best']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor()\n",
    "dt_regression = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=8, verbose=2)\n",
    "dt_regression.fit(X=train_fast_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mse',\n",
       " 'max_depth': 50,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_split': 8,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = dt_regression.predict(cv_fast_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in predicted.tolist():\n",
    "    if i<0:\n",
    "        temp.append(0.0)\n",
    "    else:\n",
    "        temp.append(i) \n",
    "        \n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression Accuracy (OneHotEcoder + TFIDF) : 0.7137738195043923\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree Regression Accuracy (OneHotEcoder + TFIDF) :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Random Forest Regression Model with OneHotEcoder + TFIDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [30],\n",
    "    'max_depth': [20, 30],\n",
    "    'min_samples_split': [8],\n",
    "    'max_features': ['sqrt']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [30],\n",
       " 'max_depth': [20, 30],\n",
       " 'min_samples_split': [8],\n",
       " 'max_features': ['sqrt']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:  2.4min remaining:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [20, 30], 'max_features': ['sqrt'],\n",
       "                         'min_samples_split': [8], 'n_estimators': [30]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "rf_regression = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=-1, verbose=2)\n",
    "rf_regression.fit(X=train_tf_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 30}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = rf_regression.predict(cv_tf_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in predicted.tolist():\n",
    "    if i<0:\n",
    "        temp.append(0.0)\n",
    "    else:\n",
    "        temp.append(i)\n",
    "        \n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Accuracy (OneHotEcoder + TFIDF) : 0.7302909019995318\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Regression Accuracy (OneHotEcoder + TFIDF) :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Random Forest Regression Model with OneHotEcoder + FastText:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [30, 50],\n",
    "    'max_depth': [20, 30, 50],\n",
    "    'min_samples_split': [8],\n",
    "    'max_features': ['sqrt']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [30, 50],\n",
       " 'max_depth': [20, 30, 50],\n",
       " 'min_samples_split': [8],\n",
       " 'max_features': ['sqrt']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  30 | elapsed:  8.5min remaining:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 30.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [20, 30, 50], 'max_features': ['sqrt'],\n",
       "                         'min_samples_split': [8], 'n_estimators': [30, 50]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "rf_regression = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=-1, verbose=2)\n",
    "rf_regression.fit(X=train_fast_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 50,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = rf_regression.predict(cv_fast_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in predicted.tolist():\n",
    "    if i<0:\n",
    "        temp.append(0.0)\n",
    "    else:\n",
    "        temp.append(i) \n",
    "        \n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Accuracy (OneHotEcoder + TFIDF) : 0.6650374823588304\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Regression Accuracy (OneHotEcoder + Fasttext) :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. AdaBoost Regression Model with OneHotEcoder + TFIDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'base_estimator': [DecisionTreeRegressor(max_depth = 1)],\n",
    "    'n_estimators': [30, 50],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'loss': ['linear', 'square']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator': [DecisionTreeRegressor(max_depth=1)],\n",
       " 'n_estimators': [30, 50],\n",
       " 'learning_rate': [0.1, 0.01],\n",
       " 'loss': ['linear', 'square']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed: 30.6min remaining: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 35.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=AdaBoostRegressor(), n_jobs=-1,\n",
       "             param_grid={'base_estimator': [DecisionTreeRegressor(max_depth=1)],\n",
       "                         'learning_rate': [0.1, 0.01],\n",
       "                         'loss': ['linear', 'square'],\n",
       "                         'n_estimators': [30, 50]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaBoostRegressor()\n",
    "\n",
    "ada_regression = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=-1, verbose=2)\n",
    "ada_regression.fit(X=train_tf_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator': DecisionTreeRegressor(max_depth=1),\n",
       " 'learning_rate': 0.01,\n",
       " 'loss': 'square',\n",
       " 'n_estimators': 30}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = ada_regression.predict(cv_tf_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in predicted.tolist():\n",
    "    if i<0:\n",
    "        temp.append(0.0)\n",
    "    else:\n",
    "        temp.append(i) \n",
    "        \n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Regression Accuracy (OneHotEcoder + TFIDF) : 0.8192359613878528\n"
     ]
    }
   ],
   "source": [
    "print('AdaBoost Regression Accuracy (OneHotEcoder + TFIDF) :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. AdaBoost Regression Model with OneHotEcoder + FastText:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'base_estimator': [DecisionTreeRegressor(max_depth = 1)],\n",
    "    'n_estimators': [30, 50],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'loss': ['square']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator': [DecisionTreeRegressor(max_depth=1)],\n",
       " 'n_estimators': [30, 50],\n",
       " 'learning_rate': [0.1, 0.01],\n",
       " 'loss': ['square']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:  7.0min remaining:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  8.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=AdaBoostRegressor(), n_jobs=-1,\n",
       "             param_grid={'base_estimator': [DecisionTreeRegressor(max_depth=1)],\n",
       "                         'learning_rate': [0.1, 0.01], 'loss': ['square'],\n",
       "                         'n_estimators': [30, 50]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaBoostRegressor()\n",
    "ada_regression = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=-1, verbose=2)\n",
    "ada_regression.fit(X=train_fast_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator': DecisionTreeRegressor(max_depth=1),\n",
       " 'learning_rate': 0.01,\n",
       " 'loss': 'square',\n",
       " 'n_estimators': 30}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = ada_regression.predict(cv_fast_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in predicted.tolist():\n",
    "    if i<0:\n",
    "        temp.append(0.0)\n",
    "    else:\n",
    "        temp.append(i) \n",
    "        \n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Accuracy (OneHotEcoder + Fasttext) : 0.8193483683404111\n"
     ]
    }
   ],
   "source": [
    "print('AdaBoost Regression Accuracy (OneHotEcoder + Fasttext) :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. LightGBM Regression Model with OneHotEcoder + TFIDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'objective': ['regression'],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'max_depth': [3, 5],\n",
    "    'n_estimators': [50, 100],\n",
    "    'num_leaves': [40]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': ['gbdt'],\n",
       " 'objective': ['regression'],\n",
       " 'learning_rate': [0.1, 0.01],\n",
       " 'max_depth': [3, 5],\n",
       " 'n_estimators': [50, 100],\n",
       " 'num_leaves': [40]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed: 26.8min remaining:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 30.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LGBMRegressor(), n_jobs=-1,\n",
       "             param_grid={'boosting_type': ['gbdt'],\n",
       "                         'learning_rate': [0.1, 0.01], 'max_depth': [3, 5],\n",
       "                         'n_estimators': [50, 100], 'num_leaves': [40],\n",
       "                         'objective': ['regression']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "\n",
    "lgbm_regression = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=-1, verbose=2)\n",
    "lgbm_regression.fit(X=train_tf_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 5,\n",
       " 'n_estimators': 100,\n",
       " 'num_leaves': 40,\n",
       " 'objective': 'regression'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikandan\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\lightgbm\\basic.py:597: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    }
   ],
   "source": [
    "predicted = lgbm_regression.predict(cv_tf_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in predicted.tolist():\n",
    "    if i<0:\n",
    "        temp.append(0.0)\n",
    "    else:\n",
    "        temp.append(i) \n",
    "        \n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Regression Accuracy (OneHotEcoder + TFIDF) : 0.6541871420915752\n"
     ]
    }
   ],
   "source": [
    "print('LGBM Regression Accuracy (OneHotEcoder + TFIDF) :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. LightGBM Regression Model with OneHotEcoder + FastText:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'objective': ['regression'],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'max_depth': [3, 5],\n",
    "    'n_estimators': [50, 100],\n",
    "    'num_leaves': [40]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': ['gbdt'],\n",
       " 'objective': ['regression'],\n",
       " 'learning_rate': [0.1, 0.01],\n",
       " 'max_depth': [3, 5],\n",
       " 'n_estimators': [50, 100],\n",
       " 'num_leaves': [40]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  40 | elapsed:   30.6s remaining:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   36.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LGBMRegressor(), n_jobs=-1,\n",
       "             param_grid={'boosting_type': ['gbdt'],\n",
       "                         'learning_rate': [0.1, 0.01], 'max_depth': [3, 5],\n",
       "                         'n_estimators': [50, 100], 'num_leaves': [40],\n",
       "                         'objective': ['regression']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "\n",
    "lgbm_regression = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=-1, verbose=2)\n",
    "lgbm_regression.fit(X=train_fast_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 5,\n",
       " 'n_estimators': 100,\n",
       " 'num_leaves': 40,\n",
       " 'objective': 'regression'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikandan\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\lightgbm\\basic.py:597: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    }
   ],
   "source": [
    "predicted = lgbm_regression.predict(cv_fast_onhot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in predicted.tolist():\n",
    "    if i<0:\n",
    "        temp.append(0.0)\n",
    "    else:\n",
    "        temp.append(i) \n",
    "        \n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Regression Accuracy (OneHotEcoder + Fasttext) : 0.6763336697112257\n"
     ]
    }
   ],
   "source": [
    "print('LGBM Regression Accuracy (OneHotEcoder + Fasttext) :', np.sqrt(mean_squared_log_error(y_cv, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Different Modelling used and observations:\n",
    "    \n",
    "    * There are eight models were used.\n",
    "    \n",
    "    * Each modle is tried with hyper parameter tunning.\n",
    "    \n",
    "    * Results of each models,\n",
    "        1. Linear Regression Model with OneHotEcoder + TFIDF                 : RMSLE --> 0.62.\n",
    "        2. Linear Regression Model with OneHotEcoder + Fasttext.             : RMSLE --> 0.66.\n",
    "        3. Ridge Regression Model with OneHotEcoder + TFIDF.                 : RMSLE --> 0.62.\n",
    "        4. Ridge Regression Model with OneHotEcoder + Fasttext.              : RMSLE --> 0.66.\n",
    "        5. Lasso Regression Model with OneHotEcoder + TFIDF.                 : RMSLE --> 0.65.\n",
    "        6. Lasso Regression Model with OneHotEcoder + Fasttext.              : RMSLE --> 0.65.\n",
    "        7. Elasticnet Regression Model with OneHotEcoder + TFIDF.            : RMSLE --> 0.63.\n",
    "        8. Elasticnet Regression Model with OneHotEcoder + Fasttext.         : RMSLE --> 0.66.\n",
    "        9. Decision Tree Regression Model with OneHotEcoder + TFIDF.         : RMSLE --> 0.72.\n",
    "        10. Decision Tree Regression Model with OneHotEcoder + Fasttext.     : RMSLE --> 0.71.\n",
    "        11. Random Forest Model with OneHotEcoder + TFIDF.                   : RMSLE --> 0.73.\n",
    "        12. Random Forest Model with OneHotEcoder + Fasttext.                : RMSLE --> 0.66.\n",
    "        13. AdaBoost Regression Model with OneHotEcoder + TFIDF.             : RMSLE --> 0.81.\n",
    "        14. AdaBoost Regression Model with OneHotEcoder + Fasttext.          : RMSLE --> 0.81.\n",
    "        15. LightGBM Regression Model with OneHotEcoder + TFIDF.             : RMSLE --> 0.65.\n",
    "        16. LightGBM Regression Model with OneHotEcoder + Fasttext.          : RMSLE --> 0.67.\n",
    "        \n",
    "    \n",
    "    * AdaBoost Regression Regression model performs better than other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Test Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikandan\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>sub_l1</th>\n",
       "      <th>sub_l2</th>\n",
       "      <th>sub_l3</th>\n",
       "      <th>contains_bundle</th>\n",
       "      <th>item_description_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlb cincinnati reds t shirt size xl</td>\n",
       "      <td>3</td>\n",
       "      <td>mlb</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>men</td>\n",
       "      <td>tops</td>\n",
       "      <td>t-shirts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>razer blackwidow chroma keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>keyboard great condition work like come box po...</td>\n",
       "      <td>electronics</td>\n",
       "      <td>computers &amp; tablets</td>\n",
       "      <td>components &amp; parts</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ava viv blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>adorable top hint lace key hole back pale pink...</td>\n",
       "      <td>women</td>\n",
       "      <td>tops &amp; blouses</td>\n",
       "      <td>blouse</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leather horse statue</td>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>new tag leather horse retail rm stand foot hig...</td>\n",
       "      <td>home</td>\n",
       "      <td>home décor</td>\n",
       "      <td>home décor accents</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24k gold plate rise</td>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>complete certificate authenticity</td>\n",
       "      <td>women</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>necklaces</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name  item_condition_id brand_name  \\\n",
       "train_id                                                                      \n",
       "0         mlb cincinnati reds t shirt size xl                  3        mlb   \n",
       "1            razer blackwidow chroma keyboard                  3      Razer   \n",
       "2                              ava viv blouse                  1     Target   \n",
       "3                        leather horse statue                  1       miss   \n",
       "4                         24k gold plate rise                  1       miss   \n",
       "\n",
       "          price  shipping                                   item_description  \\\n",
       "train_id                                                                       \n",
       "0          10.0         1                                               miss   \n",
       "1          52.0         0  keyboard great condition work like come box po...   \n",
       "2          10.0         1  adorable top hint lace key hole back pale pink...   \n",
       "3          35.0         1  new tag leather horse retail rm stand foot hig...   \n",
       "4          44.0         0                  complete certificate authenticity   \n",
       "\n",
       "               sub_l1               sub_l2              sub_l3  \\\n",
       "train_id                                                         \n",
       "0                 men                 tops            t-shirts   \n",
       "1         electronics  computers & tablets  components & parts   \n",
       "2               women       tops & blouses              blouse   \n",
       "3                home           home décor  home décor accents   \n",
       "4               women              jewelry           necklaces   \n",
       "\n",
       "          contains_bundle  item_description_score  \n",
       "train_id                                           \n",
       "0                       0                       0  \n",
       "1                       0                       3  \n",
       "2                       0                       3  \n",
       "3                       0                       3  \n",
       "4                       0                       2  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('Dataset/train_preprocessed_2.tsv', sep='\\t', index_col='train_id')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Breast cancer \"I fight like a girl\" ring</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Rings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Size 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers</td>\n",
       "      <td>1</td>\n",
       "      <td>Other/Office supplies/Shipping Supplies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers Lined...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coach bag</td>\n",
       "      <td>1</td>\n",
       "      <td>Vintage &amp; Collectibles/Bags and Purses/Handbag</td>\n",
       "      <td>Coach</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand new coach bag. Bought for [rm] at a Coac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Floral Kimono</td>\n",
       "      <td>2</td>\n",
       "      <td>Women/Sweaters/Cardigan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-floral kimono -never worn -lightweight and pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Life after Death</td>\n",
       "      <td>3</td>\n",
       "      <td>Other/Books/Religion &amp; Spirituality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Rediscovering life after the loss of a loved o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             name  item_condition_id  \\\n",
       "test_id                                                                \n",
       "0        Breast cancer \"I fight like a girl\" ring                  1   \n",
       "1        25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers                  1   \n",
       "2                                       Coach bag                  1   \n",
       "3                                   Floral Kimono                  2   \n",
       "4                                Life after Death                  3   \n",
       "\n",
       "                                          category_name brand_name  shipping  \\\n",
       "test_id                                                                        \n",
       "0                                   Women/Jewelry/Rings        NaN         1   \n",
       "1               Other/Office supplies/Shipping Supplies        NaN         1   \n",
       "2        Vintage & Collectibles/Bags and Purses/Handbag      Coach         1   \n",
       "3                               Women/Sweaters/Cardigan        NaN         0   \n",
       "4                   Other/Books/Religion & Spirituality        NaN         1   \n",
       "\n",
       "                                          item_description  \n",
       "test_id                                                     \n",
       "0                                                   Size 7  \n",
       "1        25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers Lined...  \n",
       "2        Brand new coach bag. Bought for [rm] at a Coac...  \n",
       "3        -floral kimono -never worn -lightweight and pe...  \n",
       "4        Rediscovering life after the loss of a loved o...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('Dataset/test.tsv', sep='\\t', index_col='test_id')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Reference: NLP Assigments\n",
    "def decontractions(phrase):\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = decontractions(text)\n",
    "    text = re.sub('[^A-Za-z0-9 ]+', ' ', text)\n",
    "    text = [t for t in text if t not in string.punctuation]\n",
    "    return ''.join(text)\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def removeStopWords(text):\n",
    "    word_tokens = word_tokenize(text)  \n",
    "    filtered_sentence = [w for w in word_tokens if not w in list(stop_words)] \n",
    "    filtered_sentence = ' '.join(filtered_sentence)\n",
    "    return filtered_sentence\n",
    "\n",
    "sp = spacy.load('C:/Users/Srikandan/anaconda3/envs/tensorflow_gpu/Lib/site-packages/en_core_web_sm/en_core_web_sm-2.3.1')\n",
    "\n",
    "def lemmatizer(text):\n",
    "    lem_text = sp(text)\n",
    "    lem_text = [i.lemma_ for i in lem_text]\n",
    "    return ' '.join(lem_text)\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    pat = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
    "    return re.sub(pat, '', text)\n",
    "\n",
    "def num_to_word(text):\n",
    "    digits = [int(s) for s in text.split() if s.isdigit()]\n",
    "    digits_map = {str(i): num2words(i) for i in digits}\n",
    "    for i in digits_map.keys():\n",
    "        text = text.replace(i, digits_map[i])\n",
    "    return text\n",
    "\n",
    "def remove_extra_whitespace_tabs(text):\n",
    "    pattern = r'^\\s*|\\s\\s*'\n",
    "    return re.sub(pattern, ' ', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df['name'].isna(), 'name'] = 'missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['item_description'] == 'No description yet', ['item_description']] = 'missing'\n",
    "\n",
    "test_df['item_description'].fillna('missing', inplace=True)\n",
    "\n",
    "np.unique(test_df['item_description'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['name'] = test_df['name'].apply(preprocess)\n",
    "test_df['name'] = test_df['name'].apply(lemmatizer)\n",
    "test_df['name'] = test_df['name'].apply(remove_special_characters)\n",
    "test_df['name'] = test_df['name'].apply(num_to_word)\n",
    "test_df['name'] = test_df['name'].apply(remove_extra_whitespace_tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['item_description'] = test_df['item_description'].apply(preprocess)\n",
    "test_df['item_description'] = test_df['item_description'].apply(removeStopWords)\n",
    "test_df['item_description'] = test_df['item_description'].apply(lemmatizer)\n",
    "test_df['item_description'] = test_df['item_description'].apply(remove_special_characters)\n",
    "test_df['item_description'] = test_df['item_description'].apply(num_to_word)\n",
    "test_df['item_description'] = test_df['item_description'].apply(remove_extra_whitespace_tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast cancer i fight like a girl ring</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Rings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>size seven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>1</td>\n",
       "      <td>Other/Office supplies/Shipping Supplies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coach bag</td>\n",
       "      <td>1</td>\n",
       "      <td>Vintage &amp; Collectibles/Bags and Purses/Handbag</td>\n",
       "      <td>Coach</td>\n",
       "      <td>1</td>\n",
       "      <td>brand new coach bag buy rm coach outlet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>floral kimono</td>\n",
       "      <td>2</td>\n",
       "      <td>Women/Sweaters/Cardigan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>floral kimono never wear lightweight perfect h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>life after death</td>\n",
       "      <td>3</td>\n",
       "      <td>Other/Books/Religion &amp; Spirituality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>rediscover life loss love one tony cooke paper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      name  item_condition_id  \\\n",
       "test_id                                                                         \n",
       "0                   breast cancer i fight like a girl ring                  1   \n",
       "1        twenty-five pc new seven five x12 kraft bubble...                  1   \n",
       "2                                                coach bag                  1   \n",
       "3                                            floral kimono                  2   \n",
       "4                                         life after death                  3   \n",
       "\n",
       "                                          category_name brand_name  shipping  \\\n",
       "test_id                                                                        \n",
       "0                                   Women/Jewelry/Rings        NaN         1   \n",
       "1               Other/Office supplies/Shipping Supplies        NaN         1   \n",
       "2        Vintage & Collectibles/Bags and Purses/Handbag      Coach         1   \n",
       "3                               Women/Sweaters/Cardigan        NaN         0   \n",
       "4                   Other/Books/Religion & Spirituality        NaN         1   \n",
       "\n",
       "                                          item_description  \n",
       "test_id                                                     \n",
       "0                                               size seven  \n",
       "1        twenty-five pc new seven five x12 kraft bubble...  \n",
       "2                  brand new coach bag buy rm coach outlet  \n",
       "3        floral kimono never wear lightweight perfect h...  \n",
       "4        rediscover life loss love one tony cooke paper...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast cancer i fight like a girl ring</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>size seven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coach bag</td>\n",
       "      <td>1</td>\n",
       "      <td>Coach</td>\n",
       "      <td>1</td>\n",
       "      <td>brand new coach bag buy rm coach outlet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>floral kimono</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>floral kimono never wear lightweight perfect h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>life after death</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>rediscover life loss love one tony cooke paper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      name  item_condition_id  \\\n",
       "test_id                                                                         \n",
       "0                   breast cancer i fight like a girl ring                  1   \n",
       "1        twenty-five pc new seven five x12 kraft bubble...                  1   \n",
       "2                                                coach bag                  1   \n",
       "3                                            floral kimono                  2   \n",
       "4                                         life after death                  3   \n",
       "\n",
       "        brand_name  shipping  \\\n",
       "test_id                        \n",
       "0              NaN         1   \n",
       "1              NaN         1   \n",
       "2            Coach         1   \n",
       "3              NaN         0   \n",
       "4              NaN         1   \n",
       "\n",
       "                                          item_description  \n",
       "test_id                                                     \n",
       "0                                               size seven  \n",
       "1        twenty-five pc new seven five x12 kraft bubble...  \n",
       "2                  brand new coach bag buy rm coach outlet  \n",
       "3        floral kimono never wear lightweight perfect h...  \n",
       "4        rediscover life loss love one tony cooke paper...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_1 = []\n",
    "level_2 = []\n",
    "level_3 = []\n",
    "\n",
    "cate_list = test_df['category_name'].str.split('/')\n",
    "\n",
    "for i in cate_list:\n",
    "    if i != i:\n",
    "        level_1.append('miss')\n",
    "        level_2.append('miss')\n",
    "        level_3.append('miss')\n",
    "    else:\n",
    "        level_1.append(i[0])\n",
    "        level_2.append(i[1])\n",
    "        level_3.append(i[2])\n",
    "        \n",
    "sub_l1 = pd.Series(level_1)\n",
    "sub_l2 = pd.Series(level_2)\n",
    "sub_l3 = pd.Series(level_3)\n",
    "\n",
    "test_df.drop(columns=['category_name'], inplace=True)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>sub_l1</th>\n",
       "      <th>sub_l2</th>\n",
       "      <th>sub_l3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast cancer i fight like a girl ring</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>size seven</td>\n",
       "      <td>women</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>rings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>other</td>\n",
       "      <td>office supplies</td>\n",
       "      <td>shipping supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coach bag</td>\n",
       "      <td>1</td>\n",
       "      <td>Coach</td>\n",
       "      <td>1</td>\n",
       "      <td>brand new coach bag buy rm coach outlet</td>\n",
       "      <td>vintage &amp; collectibles</td>\n",
       "      <td>bags and purses</td>\n",
       "      <td>handbag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>floral kimono</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>floral kimono never wear lightweight perfect h...</td>\n",
       "      <td>women</td>\n",
       "      <td>sweaters</td>\n",
       "      <td>cardigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>life after death</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>rediscover life loss love one tony cooke paper...</td>\n",
       "      <td>other</td>\n",
       "      <td>books</td>\n",
       "      <td>religion &amp; spirituality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      name  item_condition_id  \\\n",
       "test_id                                                                         \n",
       "0                   breast cancer i fight like a girl ring                  1   \n",
       "1        twenty-five pc new seven five x12 kraft bubble...                  1   \n",
       "2                                                coach bag                  1   \n",
       "3                                            floral kimono                  2   \n",
       "4                                         life after death                  3   \n",
       "\n",
       "        brand_name  shipping  \\\n",
       "test_id                        \n",
       "0              NaN         1   \n",
       "1              NaN         1   \n",
       "2            Coach         1   \n",
       "3              NaN         0   \n",
       "4              NaN         1   \n",
       "\n",
       "                                          item_description  \\\n",
       "test_id                                                      \n",
       "0                                               size seven   \n",
       "1        twenty-five pc new seven five x12 kraft bubble...   \n",
       "2                  brand new coach bag buy rm coach outlet   \n",
       "3        floral kimono never wear lightweight perfect h...   \n",
       "4        rediscover life loss love one tony cooke paper...   \n",
       "\n",
       "                         sub_l1           sub_l2                   sub_l3  \n",
       "test_id                                                                    \n",
       "0                         women          jewelry                    rings  \n",
       "1                         other  office supplies        shipping supplies  \n",
       "2        vintage & collectibles  bags and purses                  handbag  \n",
       "3                         women         sweaters                 cardigan  \n",
       "4                         other            books  religion & spirituality  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['sub_l1'] = sub_l1.str.lower()\n",
    "test_df['sub_l2'] = sub_l2.str.lower()\n",
    "test_df['sub_l3'] = sub_l3.str.lower()\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n",
      "['7 for all mankind®', 'abercrombie & fitch', 'acacia swimwear', 'aden & anais', 'adidas']\n"
     ]
    }
   ],
   "source": [
    "known_brand_names = list(train_df.loc[train_df['brand_name'] != '', :].sort_values('brand_name')['brand_name'].str.lower())\n",
    "\n",
    "known_brand_names = np.unique(known_brand_names)\n",
    "\n",
    "print(len(known_brand_names_up))\n",
    "print(known_brand_names_up[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df['brand_name'].isna(), 'brand_name'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>sub_l1</th>\n",
       "      <th>sub_l2</th>\n",
       "      <th>sub_l3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast cancer i fight like a girl ring</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>size seven</td>\n",
       "      <td>women</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>rings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>other</td>\n",
       "      <td>office supplies</td>\n",
       "      <td>shipping supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coach bag</td>\n",
       "      <td>1</td>\n",
       "      <td>Coach</td>\n",
       "      <td>1</td>\n",
       "      <td>brand new coach bag buy rm coach outlet</td>\n",
       "      <td>vintage &amp; collectibles</td>\n",
       "      <td>bags and purses</td>\n",
       "      <td>handbag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>floral kimono</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>floral kimono never wear lightweight perfect h...</td>\n",
       "      <td>women</td>\n",
       "      <td>sweaters</td>\n",
       "      <td>cardigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>life after death</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>rediscover life loss love one tony cooke paper...</td>\n",
       "      <td>other</td>\n",
       "      <td>books</td>\n",
       "      <td>religion &amp; spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693354</th>\n",
       "      <td>quartz crystal on flint stone</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>flint quartz cluster self mine measure 3x2 in ...</td>\n",
       "      <td>home</td>\n",
       "      <td>home décor</td>\n",
       "      <td>home décor accents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693355</th>\n",
       "      <td>PRON cosmetic travel bundle</td>\n",
       "      <td>1</td>\n",
       "      <td>IT Cosmetics</td>\n",
       "      <td>1</td>\n",
       "      <td>cosmetic travel bundle include brow power univ...</td>\n",
       "      <td>beauty</td>\n",
       "      <td>makeup</td>\n",
       "      <td>makeup sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693356</th>\n",
       "      <td>galaxy s8 hard shell case</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>new free shipping basstop case</td>\n",
       "      <td>electronics</td>\n",
       "      <td>cell phones &amp; accessories</td>\n",
       "      <td>cases, covers &amp; skins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693357</th>\n",
       "      <td>hi low floral kimono</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>floral kimono tropical print open front hi low...</td>\n",
       "      <td>women</td>\n",
       "      <td>swimwear</td>\n",
       "      <td>cover-ups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693358</th>\n",
       "      <td>freeship two floral scrub top medium</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>two floral scrub top wear less five time brown...</td>\n",
       "      <td>women</td>\n",
       "      <td>tops &amp; blouses</td>\n",
       "      <td>t-shirts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>693359 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      name  item_condition_id  \\\n",
       "test_id                                                                         \n",
       "0                   breast cancer i fight like a girl ring                  1   \n",
       "1        twenty-five pc new seven five x12 kraft bubble...                  1   \n",
       "2                                                coach bag                  1   \n",
       "3                                            floral kimono                  2   \n",
       "4                                         life after death                  3   \n",
       "...                                                    ...                ...   \n",
       "693354                       quartz crystal on flint stone                  1   \n",
       "693355                         PRON cosmetic travel bundle                  1   \n",
       "693356                           galaxy s8 hard shell case                  1   \n",
       "693357                                hi low floral kimono                  2   \n",
       "693358                freeship two floral scrub top medium                  2   \n",
       "\n",
       "           brand_name  shipping  \\\n",
       "test_id                           \n",
       "0                             1   \n",
       "1                             1   \n",
       "2               Coach         1   \n",
       "3                             0   \n",
       "4                             1   \n",
       "...               ...       ...   \n",
       "693354                        0   \n",
       "693355   IT Cosmetics         1   \n",
       "693356                        1   \n",
       "693357                        0   \n",
       "693358                        1   \n",
       "\n",
       "                                          item_description  \\\n",
       "test_id                                                      \n",
       "0                                               size seven   \n",
       "1        twenty-five pc new seven five x12 kraft bubble...   \n",
       "2                  brand new coach bag buy rm coach outlet   \n",
       "3        floral kimono never wear lightweight perfect h...   \n",
       "4        rediscover life loss love one tony cooke paper...   \n",
       "...                                                    ...   \n",
       "693354   flint quartz cluster self mine measure 3x2 in ...   \n",
       "693355   cosmetic travel bundle include brow power univ...   \n",
       "693356                      new free shipping basstop case   \n",
       "693357   floral kimono tropical print open front hi low...   \n",
       "693358   two floral scrub top wear less five time brown...   \n",
       "\n",
       "                         sub_l1                     sub_l2  \\\n",
       "test_id                                                      \n",
       "0                         women                    jewelry   \n",
       "1                         other            office supplies   \n",
       "2        vintage & collectibles            bags and purses   \n",
       "3                         women                   sweaters   \n",
       "4                         other                      books   \n",
       "...                         ...                        ...   \n",
       "693354                     home                 home décor   \n",
       "693355                   beauty                     makeup   \n",
       "693356              electronics  cell phones & accessories   \n",
       "693357                    women                   swimwear   \n",
       "693358                    women             tops & blouses   \n",
       "\n",
       "                          sub_l3  \n",
       "test_id                           \n",
       "0                          rings  \n",
       "1              shipping supplies  \n",
       "2                        handbag  \n",
       "3                       cardigan  \n",
       "4        religion & spirituality  \n",
       "...                          ...  \n",
       "693354        home décor accents  \n",
       "693355               makeup sets  \n",
       "693356     cases, covers & skins  \n",
       "693357                 cover-ups  \n",
       "693358                  t-shirts  \n",
       "\n",
       "[693359 rows x 8 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast cancer i fight like a girl ring</td>\n",
       "      <td>size seven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>floral kimono</td>\n",
       "      <td>floral kimono never wear lightweight perfect h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>life after death</td>\n",
       "      <td>rediscover life loss love one tony cooke paper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iphone six plus or sixs plus vodka pink case</td>\n",
       "      <td>one absolut vodka pink iphone six plus also fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693350</th>\n",
       "      <td>new fidget hand spinner desk toy cube</td>\n",
       "      <td>rm free shipping new highly addictive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693354</th>\n",
       "      <td>quartz crystal on flint stone</td>\n",
       "      <td>flint quartz cluster self mine measure 3x2 in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693356</th>\n",
       "      <td>galaxy s8 hard shell case</td>\n",
       "      <td>new free shipping basstop case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693357</th>\n",
       "      <td>hi low floral kimono</td>\n",
       "      <td>floral kimono tropical print open front hi low...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693358</th>\n",
       "      <td>freeship two floral scrub top medium</td>\n",
       "      <td>two floral scrub top wear less five time brown...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295525 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      name  \\\n",
       "test_id                                                      \n",
       "0                   breast cancer i fight like a girl ring   \n",
       "1        twenty-five pc new seven five x12 kraft bubble...   \n",
       "3                                            floral kimono   \n",
       "4                                         life after death   \n",
       "5             iphone six plus or sixs plus vodka pink case   \n",
       "...                                                    ...   \n",
       "693350               new fidget hand spinner desk toy cube   \n",
       "693354                       quartz crystal on flint stone   \n",
       "693356                           galaxy s8 hard shell case   \n",
       "693357                                hi low floral kimono   \n",
       "693358                freeship two floral scrub top medium   \n",
       "\n",
       "                                          item_description  \n",
       "test_id                                                     \n",
       "0                                               size seven  \n",
       "1        twenty-five pc new seven five x12 kraft bubble...  \n",
       "3        floral kimono never wear lightweight perfect h...  \n",
       "4        rediscover life loss love one tony cooke paper...  \n",
       "5        one absolut vodka pink iphone six plus also fi...  \n",
       "...                                                    ...  \n",
       "693350               rm free shipping new highly addictive  \n",
       "693354   flint quartz cluster self mine measure 3x2 in ...  \n",
       "693356                      new free shipping basstop case  \n",
       "693357   floral kimono tropical print open front hi low...  \n",
       "693358   two floral scrub top wear less five time brown...  \n",
       "\n",
       "[295525 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['brand_name'] == '', ['name', 'item_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>sub_l1</th>\n",
       "      <th>sub_l2</th>\n",
       "      <th>sub_l3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>breast cancer i fight like a girl ring</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>size seven</td>\n",
       "      <td>women</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>rings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>other</td>\n",
       "      <td>office supplies</td>\n",
       "      <td>shipping supplies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                               name  \\\n",
       "0        0             breast cancer i fight like a girl ring   \n",
       "1        1  twenty-five pc new seven five x12 kraft bubble...   \n",
       "\n",
       "   item_condition_id brand_name  shipping  \\\n",
       "0                  1                    1   \n",
       "1                  1                    1   \n",
       "\n",
       "                                    item_description sub_l1           sub_l2  \\\n",
       "0                                         size seven  women          jewelry   \n",
       "1  twenty-five pc new seven five x12 kraft bubble...  other  office supplies   \n",
       "\n",
       "              sub_l3  \n",
       "0              rings  \n",
       "1  shipping supplies  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test_df = test_df.reset_index().copy()\n",
    "temp_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>merged_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>breast cancer i fight like a girl ring size seven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                        merged_text\n",
       "0        0  breast cancer i fight like a girl ring size seven\n",
       "1        1  twenty-five pc new seven five x12 kraft bubble..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_brand_names_df = temp_test_df.reset_index().loc[temp_test_df['brand_name'] == '', ['test_id', 'name', 'item_description']]\n",
    "merged_text = unknown_brand_names_df['name'] + ' ' + unknown_brand_names_df['item_description']\n",
    "unknown_brand_names_df['merged_text'] = merged_text\n",
    "unknown_brand_names_df.drop(columns=['name', 'item_description'], inplace=True)\n",
    "unknown_brand_names_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = list(unknown_brand_names_df['test_id'])\n",
    "merged_text = list(unknown_brand_names_df['merged_text'])\n",
    "\n",
    "unknown_brand_names_map = {test_id[i] : merged_text[i] for i in range(len(test_id))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\n"
     ]
    }
   ],
   "source": [
    "known_brand_names = []\n",
    "for i in known_brand_names_up:\n",
    "    if len(i) > 2:\n",
    "        known_brand_names.append(i)\n",
    "\n",
    "print(len(known_brand_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 374/374 [00:19<00:00, 19.63it/s]\n"
     ]
    }
   ],
   "source": [
    "found_brands = {}\n",
    "found_names = {}\n",
    "\n",
    "for brand in tqdm(known_brand_names):\n",
    "    for i, j in unknown_brand_names_map.items():\n",
    "        if brand in j:\n",
    "            found_brands[i] = brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 146776/146776 [15:04<00:00, 162.36it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, j in tqdm(found_brands.items()):\n",
    "    test_df.loc[i, 'brand_name'] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>sub_l1</th>\n",
       "      <th>sub_l2</th>\n",
       "      <th>sub_l3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast cancer i fight like a girl ring</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>size seven</td>\n",
       "      <td>women</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>rings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>other</td>\n",
       "      <td>office supplies</td>\n",
       "      <td>shipping supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coach bag</td>\n",
       "      <td>1</td>\n",
       "      <td>Coach</td>\n",
       "      <td>1</td>\n",
       "      <td>brand new coach bag buy rm coach outlet</td>\n",
       "      <td>vintage &amp; collectibles</td>\n",
       "      <td>bags and purses</td>\n",
       "      <td>handbag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>floral kimono</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>floral kimono never wear lightweight perfect h...</td>\n",
       "      <td>women</td>\n",
       "      <td>sweaters</td>\n",
       "      <td>cardigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>life after death</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>rediscover life loss love one tony cooke paper...</td>\n",
       "      <td>other</td>\n",
       "      <td>books</td>\n",
       "      <td>religion &amp; spirituality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      name  item_condition_id  \\\n",
       "test_id                                                                         \n",
       "0                   breast cancer i fight like a girl ring                  1   \n",
       "1        twenty-five pc new seven five x12 kraft bubble...                  1   \n",
       "2                                                coach bag                  1   \n",
       "3                                            floral kimono                  2   \n",
       "4                                         life after death                  3   \n",
       "\n",
       "        brand_name  shipping  \\\n",
       "test_id                        \n",
       "0                          1   \n",
       "1                          1   \n",
       "2            Coach         1   \n",
       "3                          0   \n",
       "4                          1   \n",
       "\n",
       "                                          item_description  \\\n",
       "test_id                                                      \n",
       "0                                               size seven   \n",
       "1        twenty-five pc new seven five x12 kraft bubble...   \n",
       "2                  brand new coach bag buy rm coach outlet   \n",
       "3        floral kimono never wear lightweight perfect h...   \n",
       "4        rediscover life loss love one tony cooke paper...   \n",
       "\n",
       "                         sub_l1           sub_l2                   sub_l3  \n",
       "test_id                                                                    \n",
       "0                         women          jewelry                    rings  \n",
       "1                         other  office supplies        shipping supplies  \n",
       "2        vintage & collectibles  bags and purses                  handbag  \n",
       "3                         women         sweaters                 cardigan  \n",
       "4                         other            books  religion & spirituality  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df['brand_name'] == '', 'brand_name'] = 'miss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df['item_description'] == '', 'item_description'] = 'miss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(test_df[test_df['sub_l1'] == 'miss'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "concate_bundle = list(test_df['name'] + ' ' + test_df['item_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "contains_bundle = []\n",
    "a = 0\n",
    "for i in concate_bundle:\n",
    "    if (('bundles' in i) or ('bundle' in i)):\n",
    "        contains_bundle.append(1)\n",
    "    else:\n",
    "        contains_bundle.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['contains_bundle'] = contains_bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti = SentimentIntensityAnalyzer() \n",
    "def get_sentiment_score(data):\n",
    "    if data != 'miss':\n",
    "        sentence_sentiment_score = senti.polarity_scores(data)\n",
    "        compound = sentence_sentiment_score['compound']\n",
    "        if compound >= 0.5:\n",
    "            return 3 \n",
    "        if compound >= (-0.5) and compound < 0.5:\n",
    "            return 2\n",
    "        if compound < (-0.5):\n",
    "            return 1\n",
    "    else: \n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>sub_l1</th>\n",
       "      <th>sub_l2</th>\n",
       "      <th>sub_l3</th>\n",
       "      <th>contains_bundle</th>\n",
       "      <th>item_description_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast cancer i fight like a girl ring</td>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>1</td>\n",
       "      <td>size seven</td>\n",
       "      <td>women</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>rings</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>1</td>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>other</td>\n",
       "      <td>office supplies</td>\n",
       "      <td>shipping supplies</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coach bag</td>\n",
       "      <td>1</td>\n",
       "      <td>Coach</td>\n",
       "      <td>1</td>\n",
       "      <td>brand new coach bag buy rm coach outlet</td>\n",
       "      <td>vintage &amp; collectibles</td>\n",
       "      <td>bags and purses</td>\n",
       "      <td>handbag</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>floral kimono</td>\n",
       "      <td>2</td>\n",
       "      <td>miss</td>\n",
       "      <td>0</td>\n",
       "      <td>floral kimono never wear lightweight perfect h...</td>\n",
       "      <td>women</td>\n",
       "      <td>sweaters</td>\n",
       "      <td>cardigan</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>life after death</td>\n",
       "      <td>3</td>\n",
       "      <td>miss</td>\n",
       "      <td>1</td>\n",
       "      <td>rediscover life loss love one tony cooke paper...</td>\n",
       "      <td>other</td>\n",
       "      <td>books</td>\n",
       "      <td>religion &amp; spirituality</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      name  item_condition_id  \\\n",
       "test_id                                                                         \n",
       "0                   breast cancer i fight like a girl ring                  1   \n",
       "1        twenty-five pc new seven five x12 kraft bubble...                  1   \n",
       "2                                                coach bag                  1   \n",
       "3                                            floral kimono                  2   \n",
       "4                                         life after death                  3   \n",
       "\n",
       "        brand_name  shipping  \\\n",
       "test_id                        \n",
       "0             miss         1   \n",
       "1             miss         1   \n",
       "2            Coach         1   \n",
       "3             miss         0   \n",
       "4             miss         1   \n",
       "\n",
       "                                          item_description  \\\n",
       "test_id                                                      \n",
       "0                                               size seven   \n",
       "1        twenty-five pc new seven five x12 kraft bubble...   \n",
       "2                  brand new coach bag buy rm coach outlet   \n",
       "3        floral kimono never wear lightweight perfect h...   \n",
       "4        rediscover life loss love one tony cooke paper...   \n",
       "\n",
       "                         sub_l1           sub_l2                   sub_l3  \\\n",
       "test_id                                                                     \n",
       "0                         women          jewelry                    rings   \n",
       "1                         other  office supplies        shipping supplies   \n",
       "2        vintage & collectibles  bags and purses                  handbag   \n",
       "3                         women         sweaters                 cardigan   \n",
       "4                         other            books  religion & spirituality   \n",
       "\n",
       "         contains_bundle  item_description_score  \n",
       "test_id                                           \n",
       "0                      0                       2  \n",
       "1                      0                       3  \n",
       "2                      0                       2  \n",
       "3                      0                       2  \n",
       "4                      1                       2  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['item_description_score'] = test_df['item_description'].apply(lambda x: get_sentiment_score(x))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('Dataset/test_preprocessed_2.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist_item_order = {5:'poor', 4:'fair', 3:'good', 2:'almost_new', 1:'new'}\n",
    "new_item_order = {'poor':1, 'fair':2, 'good':3, 'almost_new':4, 'new':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5], dtype=int64),\n",
       " array([298992, 174531, 200798,  14789,   1191], dtype=int64))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_df['item_condition_id'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['item_condition_id'].replace(1, exist_item_order[1], inplace=True)\n",
    "test_df['item_condition_id'].replace(2, exist_item_order[2], inplace=True)\n",
    "test_df['item_condition_id'].replace(3, exist_item_order[3], inplace=True)\n",
    "test_df['item_condition_id'].replace(4, exist_item_order[4], inplace=True)\n",
    "test_df['item_condition_id'].replace(5, exist_item_order[5], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['item_condition_id'].replace(exist_item_order[1], new_item_order[exist_item_order[1]], inplace=True)\n",
    "test_df['item_condition_id'].replace(exist_item_order[2], new_item_order[exist_item_order[2]], inplace=True)\n",
    "test_df['item_condition_id'].replace(exist_item_order[3], new_item_order[exist_item_order[3]], inplace=True)\n",
    "test_df['item_condition_id'].replace(exist_item_order[4], new_item_order[exist_item_order[4]], inplace=True)\n",
    "test_df['item_condition_id'].replace(exist_item_order[5], new_item_order[exist_item_order[5]], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('Dataset/test_preprocessed_3.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>sub_l1</th>\n",
       "      <th>sub_l2</th>\n",
       "      <th>sub_l3</th>\n",
       "      <th>contains_bundle</th>\n",
       "      <th>item_description_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast cancer i fight like a girl ring</td>\n",
       "      <td>5</td>\n",
       "      <td>miss</td>\n",
       "      <td>1</td>\n",
       "      <td>size seven</td>\n",
       "      <td>women</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>rings</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>5</td>\n",
       "      <td>miss</td>\n",
       "      <td>1</td>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>other</td>\n",
       "      <td>office supplies</td>\n",
       "      <td>shipping supplies</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coach bag</td>\n",
       "      <td>5</td>\n",
       "      <td>Coach</td>\n",
       "      <td>1</td>\n",
       "      <td>brand new coach bag buy rm coach outlet</td>\n",
       "      <td>vintage &amp; collectibles</td>\n",
       "      <td>bags and purses</td>\n",
       "      <td>handbag</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>floral kimono</td>\n",
       "      <td>4</td>\n",
       "      <td>miss</td>\n",
       "      <td>0</td>\n",
       "      <td>floral kimono never wear lightweight perfect h...</td>\n",
       "      <td>women</td>\n",
       "      <td>sweaters</td>\n",
       "      <td>cardigan</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>life after death</td>\n",
       "      <td>3</td>\n",
       "      <td>miss</td>\n",
       "      <td>1</td>\n",
       "      <td>rediscover life loss love one tony cooke paper...</td>\n",
       "      <td>other</td>\n",
       "      <td>books</td>\n",
       "      <td>religion &amp; spirituality</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      name  item_condition_id  \\\n",
       "test_id                                                                         \n",
       "0                   breast cancer i fight like a girl ring                  5   \n",
       "1        twenty-five pc new seven five x12 kraft bubble...                  5   \n",
       "2                                                coach bag                  5   \n",
       "3                                            floral kimono                  4   \n",
       "4                                         life after death                  3   \n",
       "\n",
       "        brand_name  shipping  \\\n",
       "test_id                        \n",
       "0             miss         1   \n",
       "1             miss         1   \n",
       "2            Coach         1   \n",
       "3             miss         0   \n",
       "4             miss         1   \n",
       "\n",
       "                                          item_description  \\\n",
       "test_id                                                      \n",
       "0                                               size seven   \n",
       "1        twenty-five pc new seven five x12 kraft bubble...   \n",
       "2                  brand new coach bag buy rm coach outlet   \n",
       "3        floral kimono never wear lightweight perfect h...   \n",
       "4        rediscover life loss love one tony cooke paper...   \n",
       "\n",
       "                         sub_l1           sub_l2                   sub_l3  \\\n",
       "test_id                                                                     \n",
       "0                         women          jewelry                    rings   \n",
       "1                         other  office supplies        shipping supplies   \n",
       "2        vintage & collectibles  bags and purses                  handbag   \n",
       "3                         women         sweaters                 cardigan   \n",
       "4                         other            books  religion & spirituality   \n",
       "\n",
       "         contains_bundle  item_description_score  \n",
       "test_id                                           \n",
       "0                      0                       2  \n",
       "1                      0                       3  \n",
       "2                      0                       2  \n",
       "3                      0                       2  \n",
       "4                      1                       2  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>sub_l1</th>\n",
       "      <th>sub_l2</th>\n",
       "      <th>sub_l3</th>\n",
       "      <th>contains_bundle</th>\n",
       "      <th>item_description_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast cancer i fight like a girl ring</td>\n",
       "      <td>5</td>\n",
       "      <td>miss</td>\n",
       "      <td>1</td>\n",
       "      <td>size seven</td>\n",
       "      <td>women</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>rings</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>5</td>\n",
       "      <td>miss</td>\n",
       "      <td>1</td>\n",
       "      <td>twenty-five pc new seven five x12 kraft bubble...</td>\n",
       "      <td>other</td>\n",
       "      <td>office supplies</td>\n",
       "      <td>shipping supplies</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      name  item_condition_id  \\\n",
       "test_id                                                                         \n",
       "0                   breast cancer i fight like a girl ring                  5   \n",
       "1        twenty-five pc new seven five x12 kraft bubble...                  5   \n",
       "\n",
       "        brand_name  shipping  \\\n",
       "test_id                        \n",
       "0             miss         1   \n",
       "1             miss         1   \n",
       "\n",
       "                                          item_description sub_l1  \\\n",
       "test_id                                                             \n",
       "0                                               size seven  women   \n",
       "1        twenty-five pc new seven five x12 kraft bubble...  other   \n",
       "\n",
       "                  sub_l2             sub_l3  contains_bundle  \\\n",
       "test_id                                                        \n",
       "0                jewelry              rings                0   \n",
       "1        office supplies  shipping supplies                0   \n",
       "\n",
       "         item_description_score  \n",
       "test_id                          \n",
       "0                             2  \n",
       "1                             3  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('Dataset/test_preprocessed_3.tsv', sep='\\t', index_col='test_id')\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690301, 10)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(test_df[test_df['name'].isna()].index, inplace = True)\n",
    "test_df.drop(test_df[test_df['item_description'].isna()].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "52oR8wTNCapm"
   },
   "outputs": [],
   "source": [
    "brand_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "onehot_brand_xtrain = brand_encoder.fit_transform(X_train['brand_name'].values.reshape(-1, 1))\n",
    "onehot_brand_xtest = brand_encoder.transform(test_df['brand_name'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "shrbmtpPCapn"
   },
   "outputs": [],
   "source": [
    "sub1_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "onehot_sub_l1_xtrain = sub1_encoder.fit_transform(X_train['sub_l1'].values.reshape(-1, 1))\n",
    "onehot_sub_l1_xtest = sub1_encoder.transform(test_df['sub_l1'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "XswdKn2qCapn"
   },
   "outputs": [],
   "source": [
    "sub2_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "onehot_sub_l2_xtrain = sub2_encoder.fit_transform(X_train['sub_l2'].values.reshape(-1, 1))\n",
    "onehot_sub_l2_xtest = sub2_encoder.transform(test_df['sub_l2'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "C6dTBxHcCapn"
   },
   "outputs": [],
   "source": [
    "sub3_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "onehot_sub_l3_xtrain = sub3_encoder.fit_transform(X_train['sub_l3'].values.reshape(-1, 1))\n",
    "onehot_sub_l3_xtest = sub3_encoder.transform(test_df['sub_l3'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "Wpjx39DlCapo"
   },
   "outputs": [],
   "source": [
    "tfidf_name = TfidfVectorizer(ngram_range=(1, 2), min_df=2, max_features=10000)\n",
    "\n",
    "tfidf_xtrain_name = tfidf_name.fit_transform(X_train['name'].values)\n",
    "tfidf_xtest_name = tfidf_name.transform(test_df['name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "ZeQ1kiKACapo"
   },
   "outputs": [],
   "source": [
    "tfidf_description = TfidfVectorizer(ngram_range=(1, 2), min_df=10, max_features=10000)\n",
    "\n",
    "tfidf_xtrain_description = tfidf_description.fit_transform(X_train['item_description'].values)\n",
    "tfidf_xtest_description = tfidf_description.transform(test_df['item_description'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "6beiTsIYCapo"
   },
   "outputs": [],
   "source": [
    "item_condition_xtest = coo_matrix(test_df['item_condition_id'].values).reshape(len(test_df) ,1)\n",
    "shipping_xtest = coo_matrix(test_df['shipping'].values).reshape(len(test_df) ,1)\n",
    "contains_bundle_xtest = coo_matrix(test_df['contains_bundle'].values).reshape(len(test_df) ,1)\n",
    "item_description_score_xtest = coo_matrix(test_df['item_description_score'].values).reshape(len(test_df) ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "_52SAYGjCapo"
   },
   "outputs": [],
   "source": [
    "test_tf_onehot_data = hstack([onehot_brand_xtest, onehot_sub_l1_xtest, onehot_sub_l2_xtest, onehot_sub_l3_xtest, tfidf_xtest_name, tfidf_xtest_description, \n",
    "                        item_condition_xtest, shipping_xtest, contains_bundle_xtest, item_description_score_xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "VSQJMDk6Capo"
   },
   "outputs": [],
   "source": [
    "# scipy.sparse.save_npz('Featured Engineered dataset/test_tf_onehot_data.npz', test_tf_onehot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Predicting Test data using top 3 models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. AdaBoost Regression Model with OneHotEcoder + TFIDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=3),\n",
       "                  learning_rate=0.01, loss='square', n_estimators=30)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_regression = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=3), learning_rate=0.01,\n",
    "                                  loss='square', n_estimators=30)\n",
    "ada_regression.fit(X=train_tf_onehot_data, y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = ada_regression.predict(test_tf_onehot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in predicted.tolist():\n",
    "    if i<0:\n",
    "        temp.append(0.0)\n",
    "    else:\n",
    "        temp.append(i) \n",
    "        \n",
    "predicted = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame()\n",
    "output['test_id'] = test_df.reset_index()['test_id']\n",
    "output['predicted'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25.19602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25.19602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  predicted\n",
       "0        0   25.19602\n",
       "1        1   25.19602"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(693359, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1_df = pd.read_csv('Dataset/test.tsv', sep='\\t', index_col='test_id')\n",
    "test_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikandan\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3460725, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2_df = pd.read_csv('Dataset/test_stg2.tsv', sep='\\t', index_col='test_id')\n",
    "test_2_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4154084"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "693359+3460725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FE+Modelling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_gpu] *",
   "language": "python",
   "name": "conda-env-tensorflow_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
